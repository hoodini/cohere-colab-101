{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoodini/cohere-colab-101/blob/main/notebooks/guides/command-a-translate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "382b2cd9",
      "metadata": {
        "id": "382b2cd9"
      },
      "source": [
        "Automated translation from one language to another is one of the oldest applications of machine learning. Today's LLMs have proven remarkably effective for these kinds of tasks, and Command A Translate is Cohere’s state of the art entry into the machine translation field. It delivers industry-leading performance on a variety of translation tasks across 23 languages, while offering enterprises full control of their data through private deployment options.\n",
        "\n",
        "This cookbook will walk you through how to utilize Command A Translate; for more information, you can check out our [dedicated documentation](https://docs.cohere.com/docs/command-a-translate)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc0a15e",
      "metadata": {
        "id": "dfc0a15e"
      },
      "source": [
        "## Getting Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c9b38a",
      "metadata": {
        "id": "83c9b38a"
      },
      "source": [
        "First, let's install (or upgrade) the Cohere client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "74b7b979",
      "metadata": {
        "id": "74b7b979",
        "outputId": "ca4ce4c0-bc8d-4c50-9b62-3a25965b23f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-5.20.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.12.3)\n",
            "Requirement already satisfied: pydantic-core>=2.18.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.41.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from cohere) (0.22.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9.2->cohere) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.5.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers<1,>=0.15->cohere) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (1.2.0)\n",
            "Downloading cohere-5.20.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.0/319.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, fastavro, cohere\n",
            "Successfully installed cohere-5.20.1 fastavro-1.12.1 types-requests-2.32.4.20250913\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade cohere"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be00195e",
      "metadata": {
        "id": "be00195e"
      },
      "source": [
        "## Translating a Message"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ee8a07c",
      "metadata": {
        "id": "0ee8a07c"
      },
      "source": [
        "Next, we'll set up Command A Translate to complete a standard translation task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fa2bfbc2",
      "metadata": {
        "id": "fa2bfbc2",
        "outputId": "30bb216f-1d5f-49e3-9368-64575f00efef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Las empresas dependen de la traducción para algunos de sus documentos más confidenciales y críticos para su actividad, y no puede arriesgarse a que se produzcan fugas de datos, incumplimientos de la normativa o malentendidos. Los documentos mal traducidos pueden reducir la confianza y tienen implicaciones estratégicas.\n"
          ]
        }
      ],
      "source": [
        "# 1. Set up your Cohere client, translation prompt and maximum words per chunk\n",
        "import cohere\n",
        "from google.colab import userdata\n",
        "\n",
        "co = cohere.ClientV2(userdata.get('COHERE_API_KEY'))\n",
        "model = \"command-a-translate-08-2025\"\n",
        "\n",
        "target_language = \"Spanish\"\n",
        "prompt_template = \"Translate everything that follows into {target_language}:\\n\\n\"\n",
        "max_words = 15  # Set your desired maximum number of words per chunk\n",
        "\n",
        "# 2. Your source text\n",
        "text = (\n",
        "    \"Enterprises rely on translation for some of their most sensitive and business-critical documents and cannot risk data leakage, compliance violations, or misunderstandings. Mistranslated documents can reduce trust and have strategic implications.\"\n",
        ")\n",
        "\n",
        "\n",
        "# 3. Define the chunk_split function (from earlier in your notebook)\n",
        "def chunk_split(text, max_words, threshold=0.8):\n",
        "\n",
        "    words = text.split()  # Turn the text into a list of words\n",
        "    chunks = []  # Initialize an empty list to store our chunks\n",
        "    start = 0  # Starting index for slicing the words list\n",
        "\n",
        "    while start < len(words):\n",
        "        # Determine the end index for the current chunk\n",
        "        end = min(start + max_words, len(words))\n",
        "        chunk_words = words[start:end]\n",
        "        chunk_text = \" \".join(chunk_words)  # Combine words back into a string\n",
        "\n",
        "        # If we're at the end of the text or the chunk is too short, add it as is\n",
        "        if end == len(words) or len(chunk_words) < max_words * threshold:\n",
        "            chunks.append(chunk_text.strip())\n",
        "            break\n",
        "\n",
        "        # Try to find a natural breaking point within the chunk\n",
        "        split_point = None\n",
        "        for separator in [\"\\n\", \".\", \")\", \" \"]:\n",
        "            idx = chunk_text.rfind(separator)\n",
        "            if idx != -1 and idx >= len(chunk_text) * threshold:\n",
        "                split_point = idx + 1  # Position after the separator\n",
        "                break\n",
        "\n",
        "        if split_point:\n",
        "            # If a good split point is found, add the chunk up to that point\n",
        "            chunks.append(chunk_text[:split_point].strip())\n",
        "            # Move the start index forward by the number of words consumed\n",
        "            consumed = len(chunk_text[:split_point].split())\n",
        "            start += consumed\n",
        "        else:\n",
        "            # If no good split point is found, add the entire chunk\n",
        "            chunks.append(chunk_text.strip())\n",
        "            start = end  # Move to the next chunk\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# 4. Split the text into chunks using chunk_split\n",
        "chunks = chunk_split(text, max_words=max_words)\n",
        "\n",
        "# 5. Translate each chunk and collect results\n",
        "translated_chunks = []\n",
        "for chunk in chunks:\n",
        "    prompt = prompt_template.format(target_language=target_language) + chunk\n",
        "    response = co.chat(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    )\n",
        "    translated = response.message.content[0].text\n",
        "    translated_chunks.append(translated)\n",
        "\n",
        "# 6. Merge the translated chunks back together\n",
        "translated_text = \" \".join(translated_chunks)\n",
        "\n",
        "# 7. Output the final translation\n",
        "print(translated_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ace1e73",
      "metadata": {
        "id": "8ace1e73"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "To learn more, check out our dedicated [Command A Translate](/docs/command-a-translate) documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed0418f1",
      "metadata": {
        "id": "ed0418f1"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}